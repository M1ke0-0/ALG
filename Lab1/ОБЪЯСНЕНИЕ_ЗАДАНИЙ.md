# Лабораторная работа 1 — Объяснение заданий

## Задание 1: Классификация сложности (`task1_complexity.py`)

### Что нужно сделать
Определить асимптотическую сложность четырёх фрагментов кода с циклами.

### Ключевые понятия
- **Временная сложность** — как быстро растёт время работы алгоритма при увеличении n.
- **O(f(n))** — «порядок роста»; мы ищем функцию, которая ограничивает t(n) сверху.

### Как определить сложность цикла
1. Подсчитайте, сколько раз выполняется тело цикла (в зависимости от n).
2. Отбросьте константы и нестарший член.

| Цикл | Итераций | Сложность |
|------|----------|-----------|
| `for i in range(n): print(i)` | n | **O(n)** |
| Двойной цикл `range(n) × range(n)` | n × n = n² | **O(n²)** |
| `while i < n: i *= 2` | log₂(n) | **O(log n)** |
| `for i in range(n): for j in range(i)` | 0+1+…+(n−1) = n(n−1)/2 | **O(n²)** |

### Почему n(n−1)/2 → O(n²)?
В O-нотации константный множитель 1/2 отбрасывается, остаётся n², поэтому O(n(n−1)/2) = O(n²).

---

## Задание 2: Работа с нотациями (`task2_notations.py`)

### Что нужно сделать
Для четырёх функций t(n) найти три вида оценок.

### Три вида асимптотики

| Нотация | Смысл | Описание |
|---------|-------|----------|
| **O(g)** | Верхняя граница | t(n) ≤ C·g(n) для всех больших n |
| **Ω(g)** | Нижняя граница | t(n) ≥ C·g(n) для всех больших n |
| **Θ(g)** | Точная оценка | C₁·g(n) ≤ t(n) ≤ C₂·g(n); верно и O, и Ω одновременно |

### Правило нахождения
1. Найдите **старший (доминирующий) член** функции.
2. Если функция состоит из суммы, отбрасывайте все члены, кроме самого быстро растущего.
3. Отбросьте коэффициент перед доминирующим членом.

#### Примеры
- `3n² + 7n + 5` → доминирует `n²` → Θ(n²)
- `5n·log n + 20n` → доминирует `n·log n` → Θ(n log n)
- `100` → не зависит от n → Θ(1)
- `2ⁿ + n³` → доминирует `2ⁿ` (экспонента растёт быстрее любого полинома) → Θ(2ⁿ)

---

## Задание 3: Эксперимент с пузырьковой сортировкой (`task3_bubble_experiment.py`)

### Что нужно сделать
Реализовать пузырьковую сортировку, замерить время и построить два графика.

### Как работает пузырьковая сортировка
На каждом проходе сравниваются соседние элементы и меняются местами, если стоят в неверном порядке.
Самый большой элемент «всплывает» в конец. Внешний цикл — n проходов, внутренний — до n−i−1 сравнений.

```python
def bubble_sort(arr):
    n = len(arr)
    for i in range(n):              # n проходов
        for j in range(0, n-i-1):   # каждый раз чуть меньше
            if arr[j] > arr[j+1]:
                arr[j], arr[j+1] = arr[j+1], arr[j]
```

Всего операций ≈ n²/2 → **O(n²)**.

### Что показывают графики
- **График t(n)** — форма параболы → квадратичная зависимость.
- **График t(n²)** — прямая линия → значит, t ∝ n², что подтверждает O(n²).

### Зачем повторять 5 раз?
Одиночный замер может быть неточным из-за фоновых процессов ОС. Среднее из 5 повторов даёт более стабильный результат.

---

## Задание 4: Сравнение O(n²) и O(n log n) (`task4_sort_comparison.py`)

### Что нужно сделать
Сравнить по скорости пузырьковую сортировку (O(n²)) и встроенную `sorted()` (O(n log n)).

### Почему `sorted()` быстрее?
Python использует алгоритм **Timsort** — гибрид сортировки слиянием и вставками.
- Временная сложность: O(n log n) в среднем и в худшем случае.
- Реализован на C — дополнительно в ~50–100× быстрее чистого Python-кода.

### При каком n разница заметна?
При малых n (< 100) разница незначительна из-за накладных расходов.
При n ≈ 1000–2000 bubble_sort уже заметно медленнее.
При n = 10 000 разрыв достигает 50–200 раз.

### Ключевой вывод
Даже если алгоритм O(n²) написан «аккуратно», при росте n он всегда проиграет O(n log n):

```
ratio = C₁·n² / (C₂·n·log n)  =  (C₁/C₂) · n/log n  →  ∞  при n→∞
```

---

## Задание 5: Оценка времени масштабирования (`task5_scaling.py`)

### Что нужно сделать
Зная время работы алгоритма O(n log n) при n₁, оценить время при n₂.

### Формула
```
T(n) = C · n · log₂(n)

T(n₂)     n₂ · log₂(n₂)
------  =  ───────────────
T(n₁)     n₁ · log₂(n₁)
```

### Расчёт для задания
```
n₁ = 1 000 000,  T₁ = 120 мс
n₂ = 4 000 000

log₂(1 000 000) ≈ 19.93
log₂(4 000 000) ≈ 21.93

Коэффициент = (4 000 000 × 21.93) / (1 000 000 × 19.93) ≈ 4.40

T₂ = 120 × 4.40 ≈ 528 мс
```

> Для сравнения: если бы алгоритм был O(n²), время выросло бы в 4² = 16 раз → 1920 мс.

---

## Контрольные вопросы — краткие ответы

| № | Вопрос | Ответ |
|---|--------|-------|
| 1 | Почему точное t(n) затруднительно? | Зависит от железа, ОС, компилятора, данных. Асимптотика инвариантна. |
| 2 | Чем O отличается от Θ? | O — верхняя граница (может быть завышена). Θ — точная (и сверху, и снизу). |
| 3 | Чем O отличается от o? | O: f/g ≤ C (граница конечна). o: f/g → 0 (строго медленнее). |
| 4 | Почему Θ реже O? | Требует доказательства двух границ. Для разных случаев (лучший/худший) Θ может не существовать. |
| 5 | Почему при малых n поведение отличается? | Константы и дополнительные члены важны при малых n. Асимптотика верна только при n → ∞. |
