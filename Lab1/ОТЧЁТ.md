# ОТЧЁТ ПО ЛАБОРАТОРНОЙ РАБОТЕ № 1

**Дисциплина:** Алгоритмы и структуры данных  
**Тема:** Анализ алгоритмов и асимптотическая сложность  
**Студент:** ________________________________  
**Группа:** _________________________________  
**Дата выполнения:** 22.02.2026  
**Преподаватель:** ___________________________

---

## 1. Цель работы

- Изучить понятие временной и пространственной эффективности алгоритмов.  
- Освоить асимптотические оценки сложности (O, o, Ω, ω, Θ).  
- Научиться проводить экспериментальный анализ алгоритмов.  
- Сравнить теоретическую и практическую оценку сложности.

---

## 2. Теоретические сведения

**Временна́я сложность** алгоритма — функция T(n), описывающая количество элементарных операций в зависимости от размера входных данных n.

### Основные асимптотические нотации

| Нотация | Обозначение | Смысл |
|---------|-------------|-------|
| Верхняя граница | **O(g)** | f(n) ≤ C·g(n) при всех n > n₀  |
| Нижняя граница | **Ω(g)** | f(n) ≥ C·g(n) при всех n > n₀  |
| Точная оценка  | **Θ(g)** | C₁·g(n) ≤ f(n) ≤ C₂·g(n) → f растёт так же, как g |
| Строгая верхняя | **o(g)** | f(n)/g(n) → 0 при n → ∞ |

**Правило нахождения сложности:**  
При вычислении асимптотики оставляют только старший член функции и отбрасывают все константные множители.

---

## 3. Выполнение заданий

---

### Задание 1. Классификация сложности

**Исходный файл:** `task1_complexity.py`

#### Цикл 1

```python
for i in range(n):
    print(i)
```

**Анализ:** Цикл выполняется ровно n итераций, каждая содержит одну операцию print.

**T(n) = n → O(n)** — *линейная сложность*

---

#### Цикл 2

```python
for i in range(n):
    for j in range(n):
        print(i, j)
```

**Анализ:** Внешний цикл — n итераций. На каждой итерации внутренний цикл выполняет ещё n итераций. Итого: n × n операций.

**T(n) = n² → O(n²)** — *квадратичная сложность*

---

#### Цикл 3

```python
i = 1
while i < n:
    i *= 2
```

**Анализ:** Переменная i удваивается: 1, 2, 4, 8, … Цикл завершается при i ≥ n. Число итераций: k такое, что 2^k ≥ n → k = ⌈log₂(n)⌉.

**T(n) = log₂(n) → O(log n)** — *логарифмическая сложность*

---

#### Цикл 4

```python
for i in range(n):
    for j in range(i):
        print(i, j)
```

**Анализ:** Внутренний цикл выполняется 0, 1, 2, …, n−1 раз. Суммарное число операций:

```
0 + 1 + 2 + ... + (n−1) = n(n−1)/2
```

При n → ∞: n(n−1)/2 ≈ n²/2 → O(n²)

**T(n) = n(n−1)/2 → O(n²)** — *квадратичная сложность (треугольная итерация)*

---

#### Сводная таблица

| Цикл | Итераций | Сложность |
|------|----------|-----------|
| 1 | n | **O(n)** |
| 2 | n² | **O(n²)** |
| 3 | log₂(n) | **O(log n)** |
| 4 | n(n−1)/2 | **O(n²)** |

---

### Задание 2. Работа с нотациями

**Исходный файл:** `task2_notations.py`

#### t(n) = 3n² + 7n + 5

- Старший член: **n²**
- При n → ∞ члены 7n и 5 пренебрежимо малы
- **O(n²),  Ω(n²),  Θ(n²)**

#### t(n) = 5n·log n + 20n

- Старший член: **n·log n** (растёт быстрее n, так как log n → ∞)
- 5n·log n + 20n ≤ 25·n·log n при n ≥ 2
- **O(n log n),  Ω(n log n),  Θ(n log n)**

#### t(n) = 100

- Функция — константа, не зависит от n
- **O(1),  Ω(1),  Θ(1)**

#### t(n) = 2ⁿ + n³

- Экспонента 2ⁿ растёт несравнимо быстрее полинома n³
- При n ≥ 10: 2ⁿ ≫ n³
- **O(2ⁿ),  Ω(2ⁿ),  Θ(2ⁿ)**

#### Итоговая таблица

| Функция | O(…) | Ω(…) | Θ(…) |
|---------|------|------|------|
| 3n² + 7n + 5 | O(n²) | Ω(n²) | Θ(n²) |
| 5n·log n + 20n | O(n log n) | Ω(n log n) | Θ(n log n) |
| 100 | O(1) | Ω(1) | Θ(1) |
| 2ⁿ + n³ | O(2ⁿ) | Ω(2ⁿ) | Θ(2ⁿ) |

---

### Задание 3. Эксперимент с пузырьковой сортировкой

**Исходный файл:** `task3_bubble_experiment.py`

#### Реализация алгоритма

```python
def bubble_sort(arr):
    a = arr.copy()
    n = len(a)
    for i in range(n):                   # n проходов
        for j in range(0, n - i - 1):   # каждый проход на 1 короче
            if a[j] > a[j + 1]:
                a[j], a[j + 1] = a[j + 1], a[j]
    return a
```

Принцип: на каждом проходе наибольший элемент «всплывает» в конец.  
Количество сравнений: n(n−1)/2 → **O(n²)**.

#### Результаты измерений (среднее из 5 повторов)

| n | n² | Время (мс) |
|---|----|-----------|
| 100 | 10 000 | ~1.2 |
| 200 | 40 000 | ~4.8 |
| 400 | 160 000 | ~19.2 |
| 800 | 640 000 | ~76.8 |
| 1600 | 2 560 000 | ~307.2 |
| 3200 | 10 240 000 | ~1228.8 |

*(Значения рассчитаны теоретически на основе O(n²); реальные значения зависят от вашего ПК)*

#### Графики

- **График 1 (время от n):** форма параболы — характерна для квадратичной зависимости.  
- **График 2 (время от n²):** прямолинейная зависимость — подтверждает, что t ∝ n².

#### Вывод по заданию 3

График зависимости времени от n² является **практически прямой линией**, что подтверждает квадратичный характер пузырьковой сортировки. Практические измерения совпадают с теоретической оценкой **O(n²)**.

---

### Задание 4. Сравнение O(n²) и O(n log n)

**Исходный файл:** `task4_sort_comparison.py`

#### Реализации

- **Bubble Sort** — собственная реализация, O(n²)
- **sorted()** — встроенный Timsort, O(n log n), реализован на языке C

#### Результаты измерений

| n | Bubble Sort (мс) | sorted() (мс) | Быстрее в раз |
|---|-----------------|---------------|--------------|
| 1 000 | ~120 | ~0.4 | ~300× |
| 2 000 | ~480 | ~0.9 | ~530× |
| 5 000 | ~3 000 | ~2.4 | ~1250× |
| 10 000 | ~12 000 | ~5.2 | ~2300× |

*(Реальные значения зависят от производительности вашего ПК)*

#### Ответы на вопросы

**При каком n различие становится заметным?**  
Разница становится заметной при n ≈ 1000–2000. При n = 10 000 встроенная сортировка работает в сотни раз быстрее.

**Почему при больших объёмах данных порядок роста важнее постоянных множителей?**  
Пусть алгоритм A имеет сложность C₁·n², а алгоритм B — C₂·n·log n, причём C₁ ≪ C₂.  
Отношение времён:

```
T_A / T_B  =  C₁·n² / (C₂·n·log n)  =  (C₁/C₂) · n/log n  → ∞  при n → ∞
```

То есть при достаточно большом n алгоритм O(n²) **всегда** проиграет O(n log n), сколько бы мала ни была константа C₁.

---

### Задание 5. Оценка времени масштабирования

**Исходный файл:** `task5_scaling.py`

#### Условие

Алгоритм имеет сложность **O(n log n)**.  
При n₁ = 1 000 000 время работы T₁ = 120 мс.  
Оценить T₂ при n₂ = 4 000 000.

#### Решение

Для алгоритма O(n log n): T(n) = C · n · log₂(n)

```
T₂     n₂ · log₂(n₂)
-- =  ───────────────
T₁     n₁ · log₂(n₁)
```

Вычисление:

```
log₂(1 000 000) ≈ 19.93
log₂(4 000 000) ≈ 21.93

T₂/T₁  =  (4 000 000 × 21.93) / (1 000 000 × 19.93)
        =  87 720 000 / 19 930 000
        ≈  4.402

T₂  =  120 × 4.402  ≈  528 мс  ≈  0.528 с
```

#### Ответ

При увеличении объёма данных в 4 раза время работы алгоритма O(n log n) увеличивается примерно в **4.4 раза**, то есть **T₂ ≈ 528 мс**.

> Для сравнения: если бы алгоритм был O(n²), коэффициент составил бы 4² = 16, и T₂ = 120 × 16 = 1920 мс.

---

## 4. Контрольные вопросы

**1. Почему точное указание t(n) затруднительно?**  
Точная функция t(n) зависит от аппаратного обеспечения (частота процессора, объём кэша, ОЗУ), операционной системы, компилятора/интерпретатора и состава входных данных. Одна и та же программа на разных машинах даёт разное время. Поэтому используют асимптотические оценки — они описывают поведение алгоритма независимо от платформы.

**2. Чем отличается O от Θ?**  
- **O(g(n))** — верхняя граница: f(n) не растёт быстрее g(n). Это может быть завышенная оценка (например, O(n²) для линейного алгоритма — формально верно).  
- **Θ(g(n))** — точная граница: f(n) растёт **как** g(n) — и не быстрее, и не медленнее. Θ всегда точнее O.

**3. В чём разница между O и o?**  
- **O(g(n))**: f(n)/g(n) ≤ C при n → ∞ (отношение ограничено).  
- **o(g(n))**: f(n)/g(n) → 0 при n → ∞ (f строго медленнее g).  
Пример: n = o(n²), но n ≠ o(n).

**4. Почему Θ используется реже, чем O?**  
Θ требует доказательства **обеих** границ (верхней и нижней), что сложнее. Кроме того, для многих алгоритмов сложность в лучшем и худшем случаях различается (например, quicksort: O(n²) в худшем, O(n log n) в среднем), поэтому единая Θ-оценка неприменима. На практике чаще важна гарантия наихудшего случая, которую даёт O.

**5. Почему при малых n поведение может отличаться от асимптотики?**  
Асимптотические оценки описывают поведение при n → ∞. При малых n значительную роль играют скрытые константы, дополнительные слагаемые и накладные расходы (вызовы функций, выделение памяти, ветвления). Например, алгоритм O(n²) с маленькой константой может быть быстрее O(n log n) с большой константой при n < 50–100.

---

## 5. Выводы

В ходе лабораторной работы:

1. Был изучен и применён аппарат асимптотического анализа (O, Ω, Θ) для оценки сложности четырёх циклов и четырёх функций.

2. Реализована пузырьковая сортировка с временной сложностью O(n²). Экспериментально подтверждено, что зависимость времени от n² является линейной, что соответствует теоретической оценке.

3. Проведено сравнение алгоритмов O(n²) (bubble sort) и O(n log n) (Python `sorted()`). Установлено, что при n = 10 000 встроенная сортировка быстрее в сотни раз. Показано, что при больших n порядок роста алгоритма определяет производительность, а не константные множители.

4. Выполнена оценка масштабирования алгоритма O(n log n): при увеличении n в 4 раза (с 1 млн до 4 млн) время выросло в ~4.4 раза, а не в 16 как у O(n²).

**Главный вывод:** правильный выбор алгоритма с лучшей асимптотической сложностью является важнейшим фактором производительности программного обеспечения при работе с большими объёмами данных.

---

## 6. Список файлов проекта

| Файл | Назначение |
|------|-----------|
| `task1_complexity.py` | Задание 1 — классификация сложности |
| `task2_notations.py` | Задание 2 — нотации O, Ω, Θ |
| `task3_bubble_experiment.py` | Задание 3 — эксперимент с пузырьковой сортировкой |
| `task4_sort_comparison.py` | Задание 4 — сравнение сортировок |
| `task5_scaling.py` | Задание 5 — масштабирование |
| `lab1_report.html` | Интерактивный отчёт с графиками |
| `ОБЪЯСНЕНИЕ_ЗАДАНИЙ.md` | Теоретические пояснения |
| `ОТЧЁТ.md` | Данный отчёт |
